\section{Introduction}
\subsection{Software Transactional Memory and Software Transactional Objects}
Parallelism is increasingly critical for performance in computer software systems, but parallel programming remains enormously challenging to get right: ad-hoc mechanisms for coordinating threads, such as lock-based strategies, are fragile and error-prone. To address this problem, researchers have developed programming tools and methodologies for managing parallelism. Prominent among these is software transactional memory (STM), which allows programmers to write concurrent code using sequential programming paradigms. By using STM, programmers reason about concurrent operations on shared memory through transactions---groups of operations---instead of single operations. 

Unfortunately, STM often results in high overhead and is rarely considered practical. Ensuring transactional guarantees requires tracking the different memory words accessed within a transaction, and ensuring that these words are not touched by a separate, simultaneous transaction. Traditional STM tracks all words of memory read or written in a transaction \lyt{CITE}, therefore incurring an enormous overhead. Recent work at Harvard, however, has developed a novel type of STM, STO (Software Transactional Objects), that greatly improves upon the performance of traditional STM. The system's implementation works at a higher level than most previously developed systems: data structure operations, rather than individual memory words. For example, a word-STM tracks every word accessed in the path from the root during a binary search tree lookup, increasing the overhead from transactional bookkeeping and introducing unnecessary conflicts (the transaction will abort if there is a concurrent update to the path, even though the result of the lookup is unaffected). STO allows datatypes to define datatype-specific abstract objects to track instead of memory words. This results in a reduced number of false conflicts and a tracking set that contains hundreds of times fewer objects than a word-STM. 

\subsection{Motivation}
The focus of this work is to make STO as fast as the fastest concurrent programming patterns available, and when this is impossible, to precisely characterize why. Although STO outperforms traditional STM, STO’s performance still falls far below that of other concurrent programming paradigms. STO’s library of transactional datatypes---datatypes exposing transactional operations---provide the interface by which programmers use to add transactional memory to their programs. Thus, a STO program is only as fast as its datatypes. The field of datatypes algorithms offers a natural point to focus our research: by defining the limits and potentials of transactional data structure algorithms, we learn how to maximize the performance of the STO system.

\subsection{Overview}
While the scope of our claims aim to be all the different datatypes supported by STO, this work focuses on a few core data structures: queues and hashmaps. We began by implementing the first version of these STO datatypes and, more broadly, developing design techniques for transactional data structures. These techniques defined general patterns for designing transactional algorithms, such as how to handle reads and writes of the same object within the same transaction. These patterns, however, do not maximize scalability or performance.

To address our goal of performance maximization, we analyze and compare the performance of existing STO data structures against implementations of highly-concurrent data structure algorithms from recent research. These concurrent data structure algorithms strive to maximize scalability and performance without the concern for transactional correctness. Thus, discovering the fastest concurrent datatypes currently available sets an upper bound for what performance STO data structures may reasonably hope to achieve. Benchmarks highlight which concurrent data structures are the highest-performing, and which parts of the STO data structure algorithms are bottlenecks and areas for improvement. 

We began with a hypothesis that combining concurrent programming patterns with our transactional design patterns would produce transactional datatypes that greatly outperform our previous implementations. To evaluate our hypothesis, we take the fastest concurrent datatype algorithms and implement them within the STO framework. We discover that the changes we made to move highly-parallel data structures into STO results in a significant decrease in their performance; at times, they even underperformed the original STO data structure algorithms. Results from experiments with various transactional and concurrent algorithms lead us to conclude that reasoning about scalability in transactional datatypes is inherently different than reasoning about scalability in traditional concurrent datatypes. In particular, reasoning about invariants regarding datatype state is essential to handle transactions: a transactional algorithm must maintain state across operations within a transaction. 

This necessary characteristic of transactional algorithms leads us to revise our hypothesis to claim that certain high-concurrency algorithms for datatypes may be intrinsically non-transactional. To evaluate this hypothesis, we investigate how high-concurrency algorithms act when the transactional interface is modified. These interfaces allow us to better adapt concurrency datatypes algorithms for transactional settings and define the tradeoffs between the guarantees STO datatypes can provide and the performance of these datatypes.

This work as a whole is divided into 6 chapters. Chapter 2 describes background information on transactions and transactional memory as well as related work on transactional data structure algorithms. Chapter 3 is dedicated to discussing different queue algorithms, benchmarks and performance of these datatypes, and the implications of the benchmark results. Chapter 4 describes and evaluates an alternate transactional interface for the queue data structure based on the conclusions from Chapter 3. Chapter 5 discusses the hashmap algorithms and results. Finally, Chapter 6 proposes future work and concludes.
