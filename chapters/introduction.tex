\chapter{Introduction}
\section{STM and STO}
Parallelism is increasingly critical for performance in computer software systems, but parallel programming remains enormously challenging to get right: ad-hoc mechanisms for coordinating threads, such as lock-based strategies, are fragile and error-prone. To address this problem, researchers have developed programming tools and methodologies for managing parallelism. Prominent among these is software transactional memory (STM), which allows programmers to write concurrent code using sequential programming paradigms. By using STM, programmers reason about concurrent operations on shared memory through transactions---atomic groups of operations---instead of single operations. 

Unfortunately, STM often results in high overhead and is rarely considered practical. To provide transactional guarantees, an STM system tracks the different memory words accessed within a transaction and ensures that these words are not touched by a separate, simultaneous transaction. Traditional word-STM tracks all words of memory read or written in a transaction, therefore incurring an enormous overhead\cite{cascaval}. Recent work at Harvard, however, has developed a novel type of STM, STO (Software Transactional Objects), that greatly improves upon the performance of traditional STM\cite{sto}. The system's implementation works at a higher level than most previously developed systems: data structure operations, rather than individual memory words. For example, a word-STM tracks every word accessed in the path from the root during a binary search tree lookup, increasing the overhead from transactional bookkeeping and introducing unnecessary conflicts: the transaction will abort if there is a concurrent update to the path, even though the result of the lookup is unaffected. STO allows datatypes to define datatype-specific abstract objects to track instead of memory words. This results in a reduced number of false conflicts and a tracking set that contains hundreds of times fewer objects than a word-STM. 

\section{Motivation}
The focus of this work is to make STO as fast as the fastest concurrent programming patterns available, and when this is impossible, to precisely characterize why. Although STO outperforms traditional STM, STO’s performance still falls far below that of other concurrent programming paradigms. STO’s library of transactional datatypes---datatypes exposing transactional operations---allow programmers to add transactional memory to their programs. Thus, a STO program is only as fast as its datatypes. A natural focus for our research is then transactional data structure algorithms: by defining the limits and potentials of these algorithms, we learn how to maximize the performance of the STO system.

\section{Overview}
While the scope of our research aims to be all the different datatypes supported by STO, this thesis focuses on a few core data structures: queues and hashmaps. We began by implementing the first version of these STO datatypes and, more broadly, developing design techniques for transactional data structures. These techniques defined general patterns for designing transactional algorithms, such as how to handle reads and writes of the same object within the same transaction. These patterns, however, do not maximize scalability or performance.

To address our goal of performance maximization, we analyze and compare the performance of existing STO data structures against implementations of highly-concurrent data structure algorithms from recent research. These concurrent data structure algorithms strive to maximize scalability and performance without the concern for transactional correctness. Thus, the performance of the fastest concurrent datatypes currently available acts as an upper bound for what performance STO data structures may reasonably hope to achieve. Benchmarks highlight which concurrent data structures are the highest-performing, and which parts of the STO data structure algorithms are bottlenecks and areas for improvement. 

We first hypothesize that combining concurrent programming patterns with our transactional design patterns will produce transactional datatypes that greatly outperform our previous implementations. To evaluate this hypothesis, we take the fastest concurrent datatype algorithms and implement them within the STO framework. We discover that the algorithmic changes necessary to move highly-parallel data structures into STO results in a significant decrease in their performance; at times, they even underperform STO data structures that use naive algorithms for concurrency.
Furthermore, our experience combining highly-concurrent, non-transactional algorithms with transactional ones leads to the conclusion that reasoning about scalability in transactional datatypes is inherently different than reasoning about scalability in traditional concurrent datatypes. In particular, reasoning about invariants regarding datatype state is essential to handle transactions: a transactional algorithm must maintain state across operations within a transaction. We formalize this argument as a commutativity argument, drawing on previous work regarding commutativity in transactional objects\cite{weihl}.

The stateful nature of transactions (and therefore reduced operation commutativity within transactions) leads us to revise our hypothesis. From our experimental results and experiences creating transactional data structures, it seems clear that the reasoning that allows a highly-concurrent data structure to achieve fast performance and scalability is intrinsically different than the reasoning required to create a transactional, highly performant data structures. 
We claim that certain highly-concurrent algorithms for datatypes may be intrinsically non-transactional because the optimizations taken by these algorithm to achieve their high performances are incompatible with providing transactional guarantees. In other words, if the synchronization technique of a concurrent data structure interferes with the techniques required to support transactions, the data structure is unlikely to perform well in a transactional setting. Conversely, if the synchronization technique is mostly or completely independent of STO, meaning that transactional support can be added without modifying the sychronization algorithm itself, then we may still retain the benefits of the data structure's algorithmic optimizations in a transactional setting.

To evaluate our claim, we take highly-concurrent algorithms that underperformed when integrated with STO and investigate how these algorithms act when the transactional interface is modified. These interfaces allow us to better adapt concurrent datatypes algorithms for transactional settings by decreasing the dependencies between code for transactional support and the concurrent algorithm.
We show how redefining the transactional specification allows us to determine the tradeoffs between the guarantees STO datatypes can provide and their performance. We also note that highly-concurrent algorithms whose core optimizations are independent from the transactional techniques still provide performance benefits in a transactional setting.

The contributions of this work include: 
\begin{itemize}
    \item Background information on transactions and transactional memory as well as related work on transactional data structure algorithms and their scalability (Chapter~\ref{related_work}).
    \item An evaluation of different transactional and concurrent algorithms for queue and hashmap data structures (Chapters~\ref{queue} and~\ref{hashmap}).
    \item An argument based on operation commutativity and invalid histories for why concurrent algorithms for queues fail to retain their performance benefits when moved into the STO transactional framework (Chapter~\ref{queue})
    \item A demonstration of how the performance loss of queue concurrent algorithms can be elided through changing the transactional specification (Chapter~\ref{commutativity}).
    \item A demonstration of and explanation why highly-concurrent hashmap algorithms do, in fact, retain performance benefits in a transactional setting (Chapter~\ref{hashmap}).
\end{itemize}
