\chapter{Commutativity and Scalability in Transactional Queue Specifications}
\label{commutativity}

This chapter describes the commutativity of our queue operations in a transactional setting, and relates the amount of queue operation commutativity to queue implementation performance. For clarity, we refer to the queue operation interface shown in Figure~\ref{fig:q_interface} as the \emph{strong queue specification}; a transactional queue with this interface is the \emph{strong transactional queue}. We hypothesize that the strong queue specification cannot be implemented in a transactional setting in an efficient way due to the lack of operation commutativity in the strong queue specification. 
We follow this by proposing an alternative queue specification---the \emph{weak queue specification}---that allows for greater operation commutativity, and hypothesize that this alternative specification will allow for greater queue scalability.

As a supporting example of our hypotheses, we examine the flat combining technique in detail and argue that the flat combining technique cannot implement the strong queue interface efficiently in a transactional setting. While the flat-combining technique is perhaps near-optimal for a highly-concurrent data structure, it performs no better than a naive synchronization technique in a transactional data structure. This is because the flat combining algorithm's high performance comes from exploiting the greater operation commutativity present in a non-transactional setting. The flat combining algorithm's optimizations must be heavily modified in order to support transactions, which leads to significant performance loss. 

We then implement a weak transactional flat combining queue---a flat combining queue with operations satisfying the weak queue specification---with the expectation that the flat combining technique can achieve scalable performance close to its performance in a non-transactional setting. Our experimental results illustrate that the greater commutativity of operations in the weak queue specification is essential for the flat combining technique to be effective.

\section{Commutativity Terminology and Results}
We introduce some basic terminology (as defined by Schwarz~\cite{schwarz} and Weihl~\cite{weihl}) that will be used in our discussion.

\subsection{Histories}
\begin{defn}
    A \emph{history} is a sequence of \texttt{(transaction, operation, result)} tuples that represent an interleaving of operations of all committed transactions. A history also includes \texttt{(transaction, START)} and \texttt{(transaction, COMMIT)} tuples that represent the time of the transaction's start and commit, respectively. Knowledge of both the history and initial conditions of a data structure leads to complete knowledge of the (high-level) end state of the structure.

\begin{eg}
    \singlespacing   

    \begin{lstlisting}

    // Q.size() == 0 
    (T1, START)
    (T2, START)
    (T2, Q.push(a), ())
    (T1, Q.pop(), true)
    (T2, Q.push(a), ())
    (T1, Q.pop(), true)
    (T1, COMMIT)
    (T2, COMMIT)
    // Final State: Q.size() == 0 
    \end{lstlisting}
    \doublespacing
\end{eg}

\end{defn}

\begin{defn}
    A history $H'$ is \emph{consistent} with $H$ if:
    \begin{enumerate}
        \item $H'$ contains the same tuples as $H$: the same transactions were executed with the same return values for all operations within the transactions.
        \item The order of a single thread's calls in $H'$ remains consistent with the thread's order of calls in $H$.
    \end{enumerate}
\end{defn}

\begin{defn}
    A history $H$ is \emph{serial} if all tuples are grouped by transaction: if $i\le j\le k$ and $H_i$ and $H_k$ are from the same transaction, then $H_j$ is also from that transaction. This means the tuples form a serial transaction order.
\end{defn}
\begin{defn}
    A history $H$ is \emph{serializable} if there exists a serial history $H'$ s.t. $H'$ is consistent with $H$.

\end{defn}

\begin{eg}
    $H$ is a serializable history whose corresponding serial execution is $H'$. $H''$ represents a serial history, but is inconsistent with $H$ because its pop operations return different results.
\begin{figure}[H]
\singlespacing   
   \begin{tabular}{c|c|c}
H & H' & H''\\
\hline
\begin{lstlisting}
// Q.size() == 0 
(T1, START)
(T2, START)
(T2, Q.push(a), ())
(T1, Q.pop(), true)
(T2, Q.push(a), ())
(T1, Q.pop(), true)
(T1, COMMIT)
(T2, COMMIT)
\end{lstlisting} & 
\begin{lstlisting}
// Q.size() == 0 
(T2, START)
(T2, Q.push(a), ())
(T2, Q.push(a), ())
(T2, COMMIT)
(T1, START)
(T1, Q.pop(), true)
(T1, Q.pop(), true)
(T1, COMMIT)
\end{lstlisting} &
\begin{lstlisting}
// Q.size() == 0 
(T1, START)
(T1, Q.pop(), false)
(T1, Q.pop(), false)
(T1, COMMIT)
(T2, START)
(T2, Q.push(a), ())
(T2, Q.push(a), ()) 
(T2, COMMIT)
\end{lstlisting}
\end{tabular}
\end{figure}
\end{eg}

\begin{defn}
A history is \emph{linearizable} if all transactions appears to occur instantaneously between their start time and their commit time: if transaction $T1$ commits before transaction $T2$, then $T1$ must appear before $T2$ in the serial history~\cite{harristm}.
\end{defn}

\begin{defn}
    A history $H$ is \emph{strictly serializable} if it is both serializable and linearizable. Strongly-transactional specifications require strictly serializable histories.
\end{defn}

\begin{eg}
$H$ is a serializable, but not linearizable history. This is because $T2$ should have observed the pushes committed by $T1$. We can find a serial ordering of $H$, shown in $H'$, but $H'$ violates the rule that the serial order of transactions corresponds to the real time order of the transactions' commits.
    
\begin{figure}[H]
    \centering
\singlespacing   
    \begin{tabular}{c|c}
H & H'\\
\hline
\begin{lstlisting}
// Q empty                          
(T1, START)
(T1, Q.push(a), ())                
(T1, Q.push(a), ())               
(T1, Q.pop(), true)
(T1, COMMIT)
(T2, START)
(T2, Q.pop(), false)
(T2, COMMIT)
\end{lstlisting} & 
\begin{lstlisting}
// Q empty
(T2, START)
(T2, Q.pop(), false)
(T2, COMMIT)
(T1, START)
(T1, Q.push(a), ())                       
(T1, Q.push(a), ())
(T1, Q.pop(), true)
(T1, COMMIT)
\end{lstlisting}
    \end{tabular}
\end{figure}
\end{eg}

\subsection{Dependencies}

Note that all operations can be classified as sets of reads and/or writes (as we do in Table~\ref{table:qrw}). We therefore define dependencies abstractly as reads and writes of particular objects in our definitions.

\begin{defn}
    A \emph{dependency} between transaction $T2$ and transaction $T1$ can be defined as one of the following relations:
    \begin{itemize}
        \item $R_1$-$R_2$: $T2$ reads an object previously read by $T1$
        \item $R_1$-$W_2$: $T2$ writes an object previously read by $T1$
        \item $W_1$-$R_2$: $T2$ reads an object previously written by $T1$
        \item $W_1$-$W_2$: $T2$ writes an object previously written by $T1$
    \end{itemize}
    Dependencies between two transactions form a dependency graph, where transactions are the vertices and labeled, undirected edges indicate different types of dependencies between them.
\end{defn}

\begin{defn}
    An operation performed by $T1$ \emph{commutes} with an operation of $T2$ when the operations form a \emph{R-R} dependency or no dependency at all~\cite{weihl}.
\end{defn}

\begin{defn}
    A \emph{dependency cycle} is a cycle of dependency edges between two transactions. An \emph{invalid dependency cycle} is a cycle consisting of only \emph{R-W}, \emph{W-R}, or \emph{W-W} dependency edges between two transactions. Note that an invalid dependency cycle cannot be generated by only operations that commute.
\end{defn}
\begin{eg}
    $R_1$-$W_2$-$W_1$ is an invalid dependency cycle between $T1$ and $T2$.
    $R_1$-$R_1$-$W_1$ is a dependency cycle, but not an invalid one.
\end{eg}

\subsection{Commutativity and Serializability Results}

These results are well-known in the literature about transactional data structure scalability; we repeat them here for reference.
A history $H$ is serializable if there are no invalid dependency cycles in the dependency graph (see Schwarz's proof~\cite{schwarz}). This implies that when two operations commute, exchanging the order in which they occur in the history does not affect the serializability of the history: swapping the order of the two operations in the history will not introduce a new invalid dependency cycle in the dependency graph. From this, it follows that the number of valid histories of a strongly-transactional data structure is dependent on the commutativity of its operations.
Because the data structure must prevent fewer invalid histories when operation commutativity increases, greater operation commutativity also determines the data structure's scalability. 
%This result is formalized by the \emph{scalable commutativity rule}: whenever interface operations commute, they can be implemented in a way that scales~\cite{scrule}.

\section{Commutativity of Strongly-Transactional Queues}

For generality, we reduce each queue operation to a read or write of a particular semantic object: the \texttt{head}, the \texttt{tail}, or the \texttt{empty?} predicate of the queue. This allows for our reasoning to be applied to push or pop operations that differ from our current specification of pop or push. For example, we can imagine an alternative pop operation that returns \texttt{void} regardless of whether the queue was empty, which would perform no visible reads. We summarize the reads and writes of our pop and push specifications in Table~\ref{table:qrw}.

\begin{table}[t]
\centering
\begin{tabular}{c||c|c}
    Operation & Read & Write\\
    \hline
    pop & \texttt{empty?} & \texttt{head}, \texttt{empty?}\\
    push & & \texttt{tail}, \texttt{empty?}\\
\end{tabular}
    \caption[Objects read or written by queue operations]{Objects read or written by queue operations. A push or pop only performs a write of \texttt{empty?} if it changes the empty status of the queue.}
    \label{table:qrw}
\end{table}

Any queue satisfying a transactional specification must first synchronize individual operations for concurrent correctness. To determine which queue operations need synchronization, we examine the dependencies generated by singleton transactions (Table~\ref{tab:queuesimpledeps}). Dependencies generated by singleton transactions indicate which operations need to be synchronized for concurrent correctness: two operations need to be synchronized if there is a non-$R$-$R$ dependency between them.%
\footnote{We note that we use the dependencies of singleton transactions to determine when two operations must be synchronized in a concurrent, non-transactional queue. This requires that the concurrent, non-transactional queue satisfy the guarantees of a transactional data structure performing singleton transactions.
The flat combining technique provides serializable, atomic, and linearizable singleton transactions~\cite{flatcombining}. We can therefore use transactional dependencies of singleton transactions to reason about when the concurrent, non-transactional flat combining queue must add mechanisms to ensure correct synchronization.

In general, however, the guarantees of concurrent, non-transactional queues are almost, but not exactly, equivalent to that of singleton transactions. A history of singleton transactions is automatically serializable: the history corresponding to the ordering of operation execution is a serial ordering of transactions. The atomicity of transactions is guaranteed by the correctness properties of the concurrent data structure. However, single operations are not always linearizable: depending on the implementation of the data structure, the effects of a operation $P$ that has ``committed'' (i.e., has returned) may not be visible to an operation that is performed after $P$ returns. An example of this is the Stone concurrent queue~\cite{stone}, in which a slow enqueue may cause a subsequent dequeue to observe an empty queue.}
A concurrent, non-transactional queue therefore needs only to ensure correct synchronization when two threads attempt to write ($W$-$W$) the same object, or when one thread writes and another thread simultaneously reads ($W$-$R$ or $R$-$W$) the same object: synchronizing concurrent access is the main performance bottleneck. As we have shown, the flat combining approach works particularly well in a highly-concurrent setting to minimize the overhead of this synchronization cost.

\begin{table}[t]
    \singlespace
    \centering
    \begin{tabular}{|l|c|}
        \hline
        \multicolumn{1}{|c|}{Interleaving} & Generated Dependencies\\
        \hline

\begin{lstlisting}
(T1, Q.pop(), true/false) 
(T2, Q.pop(), true/false)
\end{lstlisting} &
W$_1$-W$_2$, R$_1$-W$_2$, W$_1$-R$_2$
       \\ 
    \hline
\begin{lstlisting}
(T1, Q.push(a), ())
(T2, Q.push(a), ())
\end{lstlisting} &
W$_1$-W$_2$
\\
\hline
\begin{lstlisting}
(T1, Q.pop(), true/false) 
(T2, Q.push(a), ()) 
\end{lstlisting} &
        R$_1$-W$_2$, W$_1$-W$_2$
       \\ 
    \hline
\begin{lstlisting}
(T1, Q.push(a), ())
(T2, Q.pop(), true)
\end{lstlisting} &
        W$_1$-R$_2$, W$_1$-W$_2$
\\
    \hline
\end{tabular}
    \caption[Queues dependencies generated by singleton transactions that require synchronization.]{Queue dependencies generated by singleton transactions that require synchronization.

    A write of \texttt{empty?} occurs only when the operation changes the empty status of the queue; dependencies generated by these writes are included. R-R dependencies are omitted because they do not require synchronization.
}
    \label{tab:queuesimpledeps}
\end{table}

\subsection{Invalid Dependency Cycles and Scalability}
\label{dep_cycles}

\begin{table}
    \centering
    \begin{tabular}{|c|l|c|}
        \hline
\multicolumn{2}{|c|}{Interleaving} & Generated Dependency Cycle\\
        \hline
1. & 
\begin{lstlisting}
(T1, Q.pop(), true/false)  
(T2, Q.pop(), true/false)       
(T1, Q.pop(), true/false)
\end{lstlisting} &

\begin{tabular}[x]{@{}c@{}}
        W$_1$-W$_2$-W$_1$, R$_1$-W$_2$-W$_1$, W$_1$-R$_2$-W$_1$, \\
        R$_1$-W$_2$-R$_1$, W$_1$-W$_2$-R$_1$
\end{tabular} \\
    \hline
        2. & 
\begin{lstlisting}
// Q.size() == 1  
(T1, Q.pop(), true) // Q empty  
(T2, Q.push(a), ())
(T1, Q.pop(), true)
\end{lstlisting} &
R$_1$-W$_2$-R$_1$
       \\ 
    \hline
        3. & 
\begin{lstlisting}
// Q.size() == 1  
(T1, Q.pop(), true)  // Q empty  
(T2, Q.pop(), false)
(T1, Q.push(a), ())
\end{lstlisting} &
W$_1$-W$_2$-W$_1$, W$_1$-R$_2$-W$_1$
\\
\hline
        4. &
\begin{lstlisting}
(T1, Q.push(a), ()) 
(T2, Q.push(a), ())
(T1, Q.push(a), ())
\end{lstlisting} &
W$_1$-W$_2$-W$_1$
\\
\hline
        5. &
\begin{lstlisting}
// Q.size() == 0 
(T1, Q.push(a), ())       
(T2, Q.pop(), true)  // Q empty
(T1, Q.pop(), false) 
\end{lstlisting} &
W$_1$-R$_2$-W$_1$, W$_1$-W$_2$-W$_1$
\\
    \hline
\end{tabular}
    \caption[Invalid dependency cycles of a strongly-transactional queue.]{Invalid dependency cycles of a strongly-transactional queue. 
    
    A write of \texttt{empty?} occurs only when the operation changes the empty status of the queue. We show only those specific scenarios that encounter empty queues and therefore generate writes, creating invalid dependencies cycles.}
    \label{tab:interleavings}
\end{table}

A transactional queue specification defines which histories are considered valid. A queue satisfying a transactional specification must therefore ensure both correct single-operation synchronization and that only valid histories---as defined by the specification---occur.
A strongly-transactional specification requires strict serializability, which means that all invalid dependency cycles---dependency cycles caused by operations that do not commute---can never occur in the history. Note that invalid cycles are created only with multi-operation transactions, as there are no non-trivial interleavings when all transactions contain only one operation.

Defining a dependency cycle as an invalid dependency cycle requires knowledge of the queue operation interface, since the queue operation interface defines the reads and writes of each operation. The possible interleavings that generate invalid dependency cycles in a queue satisfying our queue operation interface (Figure~\ref{fig:q_interface}) and the strongly-transactional specification are shown in Table~\ref{tab:interleavings}. Nearly all of these interleavings occur when the queue becomes empty. We only see invalid dependency cycles in a nonempty queue if both transactions push or both transactions pop (creating a \emph{W-W-W} dependency cycle). 

A strongly-transactional queue algorithm must therefore both correctly synchronize single operations (handle dependencies between singleton transactions), and prevent invalid dependency cycles that can form between transactions. This requires, as indicated by the transactional commit protocol, that a transactional algorithm provide methods to perform the operation both at execution and at install time, to check that it did not observe something that another transaction did that would make its operation results invalid (i.e., create an invalid dependency cycle), and to undo any eagerly-made updates if it must abort. 

We hypothesize that any implementation of our queue interface that satisfies the strongly-transactional specification will not scale. This is because a pop operation in one transaction never commutes with any operation performed by another transaction when encountering an empty queue, and pops performed in two separate transactions never commute. Because of this lack of operation commutativity, the transactional queue specification has a large number of invalid dependency cycles that must be handled; this prevents efficient implementation of a transactional queue with our interface. To demonstrate how our queue interface and the corresponding commutativity of pop operations prevent a scalable strongly-transactional queue implementation, imagine a different queue interface in which a pop operation returns \texttt{void} instead of \texttt{bool}. A transaction executing a pop would not observe the empty status of the queue, which would allow a pop to commute with all other operations in the history (exchanging the order of a pop and another operation would have no observable effect to the caller). With this interface, a queue satisfying the strongly-transactional specification could simply execute all operations at commit time using any concurrent queue algorithm, and do nothing (except return \texttt{void}) at execution time. This would make the queue equally as scalable as any concurrent queue algorithm.

\subsection{Commutativity and Flat Combining Performance}
An example of a queue algorithm that cannot effectively implement a strongly-transactional queue with our queue interface is the flat combining algorithm. 
Flat combining's fundamental principle is that all requests posted to the publication list commute with each other: the combiner thread can blindly apply operations on the publication list in an arbitrary order. In a strongly-transactional queue with our queue interface, push and pop operations will no longer always commute.
This requires additional complexity of each flat combining call (pop and push) and additional flat combining calls to check, undo, or install at commit time. We describe several methods to do so below, and argue that these methods cannot be integrated with the flat combining algorithm without introducing overhead that reduces its performance to below that of the T-QueueO or T-QueueP.

There are several methods for preventing cyclic dependencies from forming (i.e., preventing invalid operation interleavings from occurring in the history). For example, a standard method for a transactional queue is to delay push operation execution, and to use a pessimistic or optimistic approach when encountering an empty queue. This method can prevent all invalid interleavings shown in Table~\ref{tab:interleavings}.

To prevent interleavings 4 and 5, all pushes are delayed until commit time. These interleavings can occur only if $T1$'s first push is visible to $T2$ prior to $T1$'s commit. If we delay pushes until commit time, $T2$ will not detect the presence of a pushed item in the queue.

Because pop operations immediately return values that depend on the state of the queue (\texttt{false} if the queue is empty or \texttt{true} if the queue is nonempty), interleavings 1, 2, and 3 cannot be prevented by delaying pop operations until commit time. Instead, we can take one of two approaches. Let $T1$ be a transaction that has performed a pop.
\begin{enumerate}
    \item Optimistic: Abort $T1$ at commit time if $T2$ has committed an operation that would cause an invalid interleaving.
    \item Pessimistic: Prevent $T2$ from committing any operation until after $T1$ commits or aborts.
\end{enumerate}

The T-QueueO implements the optimistic method: checks of the tail version and the head version determine at commit time whether the empty status of the queue has been modified by another, already committed transaction. The T-QueueP implements the pessimistic approach, which locks the queue after a pop is performed and only releases the lock if the transaction commits or aborts, therefore preventing any other transaction from committing any operation after the pop.

The flat combining approach can do either approach (1) or (2) to support transactions; however, the flat combining approach cannot do either without introducing overhead that reduces its performance to below that of the T-QueueO or T-QueueP.

If we take approach (1), a pop cannot be performed at execution time because no locks on the queue are acquired at execution time: other transactions are allowed to commit pops, which may pop an invalid head if this transaction aborts. Thus, in order to determine if a pop should return true or return false, a transactional pop flat combining request requires much more complexity than a non-transactional one: the thread must determine how many elements the queue holds, how many elements the current transaction is intending to pop, and if any other thread intends to pop (in which case the transaction aborts). The transactional push flat combining request is also more complex, as it requires installing all the pushes of the transaction. Additional flat combining calls are necessary to allow a thread to perform checks of the queue's empty status (the \texttt{<EMPTY?>} flat combining call) to determine whether the transaction can commit or must abort, and to actually execute the pops at commit time. Thus, approach (1) requires adding both more flat combining calls and more complexity to the existing flat combining calls.

If we take approach (2), the flat combining approach can either perform a pop at execution time or delay the pop until commit time. If the pop is performed at execution time, then the thread must acquire a global lock on the queue after a pop and hold the lock until commit: this prevents another thread from observing an inconsistent state of the queue. If a pop removes the head of the queue prior to commit and the transaction later aborts, the popped element must be re-attached to the head of the queue. Any thread performing a pop must acquire a global lock to ensure that no other thread can commit a transaction that pops off the incorrect head of the queue (given that elements may be reattached to the head if the transaction aborts). Additional flat combining calls are necessary to acquire or release the global lock. 

We can also imagine a mix of approaches (1) and (2). If a transaction $T1$ executes a pop, we can disallow any pops from other transactions (using the equivalent of a global lock) but allow other transactions containing only pushes to commit prior to $T1$ completing. This approach prevents interleavings 1 and 3, but requires performing a check of the queue's empty status, as in approach (1), if a pop saw the queue in an empty state. This is because another transaction may have committed a push between the time of $T1$'s pop and $T1$'s completion. This mixed approach outperforms both approach (2) and approach (1), and is the approach described as the flat combining algorithm in Chapter~\ref{queue}. 

As previously noted, all possible approaches to prevent interleavings 1, 2, and 3 rely on implementing additional flat combining calls and increasing the complexity of previously existing flat combining calls. In addition, acquisition of a global ``lock'' on the queue for approach (2) prevents the combiner thread from applying \emph{all} of the requests it sees; instead, requests will either return ``abort'' to the calling thread or not be applied, leading to additional time spent spinning or repeating requests. These modifications to the flat combining algorithm allow the combiner thread to prevent the interleavings that lead to invalid dependency cycles in the strongly-transactional specification.

We see through our experiments that these changes to the flat combining algorithm reduce its performance such that it performs worse than a naive synchronization algorithm; furthermore, we claim that these changes, or changes similar in nature, are necessary in order to provide transactional guarantees. The original flat combining algorithm exploits the property that any correct history of operations in data structures supporting only singleton transactions (i.e., a concurrent, non-transactional data structure) is valid. The combiner thread is allowed to immediately apply all threads' operation requests in arbitrary order. However, this property that makes flat combining so performant disappears as soon as the algorithm has to deal with non-serializable histories. In the next section, we demonstrate how changing the transactional specification to allow for greater operation commutativity leads to a version of flat combining that can outperform our T-QueueO and T-QueueP algorithms: this supports our claim that the flat combining algorithm's performance is heavily dependent on what types of transactional guarantees it must provide.
