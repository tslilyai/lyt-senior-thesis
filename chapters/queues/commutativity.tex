\chapter{Commutativity and Weakly Transactional Queues}
\label{commutativity}

We first describe the commutativity of queue operations in high-concurrent, non-transactional settings and compare it to the commutativity of queue operations in a fully-transactional setting. We then argue that the flat combining technique, while perhaps near-optimal for a highly-concurrent data structure, is no better for performance than a naive synchronization technique in a transactional data structure. This is because the flat combining algorithm's high performance comes from exploiting the greater operation commutativity present in a non-transactional setting. Thus, to support transactions, the flat combining algorithm's optimizations must be heavily modified. 

To demonstrate this point, we propose a transactional specification that allows greater operation commutativity with the expectation that the flat combining technique can achieve better performance under this specification. Our experimental results illustrate that the commutativity of operations in this new setting is essential for the effectiveness of the flat combining technique.

\section{Terminology}
We first introduce some basic terminology (as defined by Schwarz~\cite{schwarz} and Weihl~\cite{weihl}) that will occur in our discussion.

\subsection{Histories}
\begin{defn}
    A \emph{history} is a sequence of \texttt{(transaction, operation, result)} tuples that represent an interleaving of operations of all committed transactions. Knowledge of both the history and initial conditions of a data structure leads to complete knowledge of the (high-level) end state of the structure and operation return values.

\begin{eg}
    \singlespacing   

    \begin{lstlisting}

    // Q.size() == 0 
    (T2, Q.push(a), ())
    (T1, Q.pop(), true)
    (T2, Q.push(a), ())
    (T1, Q.pop(), true)
    // Final State: Q.size() == 0 
    \end{lstlisting}
    \doublespacing
\end{eg}

\end{defn}

\begin{defn}
    A history $H'$ is \emph{consistent} with $H$ if:
    \begin{enumerate}
        \item $H'$ contains the same tuples as $H$: the same transactions were executed with the same return values for all operations within the transactions.
        \item The order of a single thread's calls in $H'$ remains consistent with the thread's order of calls in $H$.
    \end{enumerate}
\end{defn}

\begin{defn}
    A history $H$ is \emph{serial} if all tuples are ordered as if all transactions were executed in a serial order.
\end{defn}
\begin{defn}
    A history $H$ is \emph{serializable} if there exists a serial history $H'$ s.t. $H'$ is consistent with $H$.

\end{defn}

\begin{eg}
$H$ is a serializable history whose corresponding serial execution is $H'$. $H''$ represents a serial history but is inconsistent with $H$.
\begin{figure}[H]
\singlespacing   
   \begin{tabular}{c|c|c}
H & H' & H''\\
\hline
\begin{lstlisting}
(T2, Q.push(a), ())
(T1, Q.pop(), true)
(T2, Q.push(a), ())
(T1, Q.pop(), true)
\end{lstlisting} & 
\begin{lstlisting}
(T2, Q.push(a), ())
(T2, Q.push(a), ())
(T1, Q.pop(), true)
(T1, Q.pop(), true)
\end{lstlisting} &
\begin{lstlisting}
(T1, Q.pop(), false)
(T1, Q.pop(), false)
(T2, Q.push(a), ())
(T2, Q.push(a), ()) 
\end{lstlisting}
\end{tabular}
\end{figure}
\end{eg}

\begin{defn}
    A history $H$ is \emph{strictly serializable} and therefore \emph{valid} if it is both serializable and all operations are linearizable. Informally, \emph{linearizability} means that a transaction appears to occur instantaneously between the time of its start and the time of its commit.
\end{defn}

\begin{eg}
$H$ is a serializable but not linearizable history. $H'$ is a valid serial ordering of $H$, but violates the rule that the serial order of transactions corresponds to the real time at which the transactions committed.
    
\begin{figure}[H]
\singlespacing   
    \begin{tabular}{c|c}
H & H'\\
\hline
\begin{lstlisting}
// Q empty                          
(T1, Q.push(a), ())                
(T1, Q.push(a), ())               
(T1, Q.pop(), true)  // T1 commits
(T2, Q.pop(), false) // T2 commits
\end{lstlisting} & 
\begin{lstlisting}
// Q empty
(T2, Q.pop(), false) // T2 commits
(T1, Q.push(a), ())                       
(T1, Q.push(a), ())
(T1, Q.pop(), false)// T1 commits
\end{lstlisting}
    \end{tabular}
\end{figure}
\end{eg}

\subsection{Dependencies}

Note that all operations can be classified as sets of reads and/or writes (as we do in Table~\ref{table:qrw}). We therefore define dependencies abstractly as reads and writes of particular objects in our definitions.

\begin{defn}
    A \emph{dependency} between transaction $T2$ and transaction $T1$ can be defined as one of the following relations:
    \begin{itemize}
        \item R-R: $T2$ reads an object previously read by $T1$
        \item R-W: $T2$ writes an object previously read by $T1$
        \item W-R: $T2$ reads an object previously written by $T1$
        \item W-W: $T2$ writes an object previously written by $T1$
    \end{itemize}
    Dependencies between two transactions form a dependency graph, where transactions are the vertices and labeled edges indicate different types of dependencies between them.
\end{defn}

\begin{defn}
    Operation $p$ performed by $T1$ \emph{commutes} with operation $q$ of $T2$ when the operations form a \emph{R-R} dependency or no dependency at all.
(definition taken from Weihl~\cite{weihl}).
\end{defn}

\subsection{Results}

These results are well-known in the literature about transactional data structure scalability: we repeat them here for reference.
\begin{theorem}
    A history $H$ is serializable if there are no cycles in \emph{R-W}, \emph{W-R}, or \emph{W-W} dependencies between any two transactions in the dependency graph (see ~\cite{schwarz} for proof).
\end{theorem}

\begin{theorem}
    When operations commute, they can be freely ordered in the history without affecting serializability (follows from definition of commutativity).\lyt{check}
\end{theorem}

\begin{corollary}
    The number of valid histories of a transactional data structure is dependent on the commutativity of its operations.
\end{corollary}

\begin{corollary}
    Commutativity of data structure operations determines scalability: the greater number of valid histories, the lower the contention between transactions, and the greater the scalability of the transactional data structure. 
\end{corollary}

\section{Commutativity of Concurrent and Transactional Queues}

For generality, we reduce each queue operation to a read or write of a particular semantic object: the \texttt{head}, the \texttt{tail}, or the \texttt{empty?} predicate of the queue. This allows for our reasoning to be applied to operations that differ from our current specification of pop or push. For example, we can imagine an alternative pop operation that returns \texttt{void} regardless of whether the queue was empty, which would perform no visible reads. We summarize the reads and writes of our pop and push specifications in Table \ref{table:qrw}.

\begin{table}[t]
\centering
\begin{tabular}{c||c|c}
    Operation & Read & Write\\
    \hline
    pop & \texttt{empty?} & \texttt{head}, \texttt{empty?}\\
    push & & \texttt{tail}, \texttt{empty?}\\
\end{tabular}
    \caption{Objects read or written by queue operations}
    \label{table:qrw}
\end{table}

\subsection{Concurrent Non-Transactional Queues}

The guarantees of concurrent, non-transactional queues are \emph{nearly} equivalent to that of singleton transactions. A history of singleton transactions is automatically serializable, since the history corresponding to the ordering of operation execution is a serial ordering of transactions. The atomicity of transactions is guaranteed by the correctness properties of the concurrent data structure. However, single operations are not always linearizable: depending on the implementation of the data structure, the effects of a operation $P$ that has ``committed'' (i.e., has returned), may not be visible to an operation that is performed after $P$ returns.

The flat combining technique provides serializable, atomic, \emph{and} linearizable singleton transactions~\cite{flatcombining}. Therefore, we can reason about the commutativity and therefore scalability of a concurrent, non-transactional flat combining queue using notions of transactional dependencies.

We start by defining the dependency relations between single operations (Table~\ref{table:queuesimpledeps}). A concurrent, non-transactional queue cannot have any cyclical dependencies, since such dependencies necessarily require that there exists a transaction with more than one operation. Therefore, synchronization is only necessary to ensure correctness when two threads attempt to write (W-W) or simultaneously write/read (W-R or R-W) the same object: the performance bottleneck is only caused by concurrent access synchronization. As we have shown, the flat combining approach works particularly well in a highly-concurrent setting to minimize the overhead of this synchronization cost.

\begin{table}[t]
    \centering
\begin{tabular}{c||c|c|c|c}
    Object & Pop-Pop & Pop-Push & Push-Pop & Push-Push\\
    \hline
    head & W-W & & & \\
    tail & & & & W-W\\
    empty & W$^e$-R & R-W$^e$ & W$^e$-R, W$^e$-W$^e$ & \\
\end{tabular}
    \caption*{X-Y represents an operation X performed by one thread and an operation Y performed by another thread.\\$^e$ indicates that the operation modifies the empty status of the queue.\\R-R relations are not shown.}
    \caption{Dependencies of pairs of queue operations}
    \label{table:queuesimpledeps}
\end{table}

\subsection{Transactional Queues}

\begin{table}
    \centering
    \begin{tabular}{|l|}
        \hline
\begin{lstlisting}
1) // Q.size() > 1 
   (T1, Q.pop(), true)  
   (T2, Q.pop(), true)       // W-W
   (T1, Q.pop(), true/false) // W-W
\end{lstlisting}
       \\ 
    \hline
\begin{lstlisting}
2) // Q.size() == 1  
   (T1, Q.pop(), true) // Q empty  
   (T2, Q.push(a), ()) // R-W
   (T1, Q.pop(), true) // W-R
    \end{lstlisting}
       \\ 
    \hline
\begin{lstlisting}
3) // Q.size() == 1  
   (T1, Q.pop(), true)  // Q empty  
   (T2, Q.pop(), false) // W-W     
   (T1, Q.push(a), ())  // R-W     
   \end{lstlisting} 
\\
\hline
\begin{lstlisting}
4) // Q.size() >= 0 
   (T1, Q.push(a), ()) 
   (T2, Q.push(a), ()) // W-W
   (T1, Q.push(a), ()) // W-W
\end{lstlisting}
\\
\hline
\begin{lstlisting}
5) // Q.size() == 0 
   (T1, Q.push(a), ())       
   (T2, Q.pop(), true)  // W-R, Q empty
   (T1, Q.pop(), false) // W-W
\end{lstlisting}
\\
    \hline
\end{tabular}
    \caption*{Interleavings that create R-R dependencies or no dependencies are omitted.}
    \caption{Operation interleavings generating dependency cycles.}
    \label{tab:interleavings}
\end{table}

With a fully-transactional queue, cyclical dependencies can occur, thus reducing the number of valid histories. The possible interleavings that generate cyclical dependencies are shown in Table~\ref{tab:interleavings}. Note that most of the interleavings that result in cyclical dependencies, and therefore invalid histories, occur when the queue becomes empty. 
We only see cyclical dependencies in a nonempty queue if both transactions push or pop (a $W-W$ dependency).

A transactional queue prevents these interleavings from occurring through delaying push operation execution and using a pessimistic or optimistic approach upon encountering an empty queue.

To prevent interleavings 4 and 5, all pushes are delayed until commit time. These interleavings can only occur if $T1$'s first push is visible to $T2$ prior to $T1$ committing. If we delay pushes until commit time, $T2$ will not detect the presence of a pushed item in the queue.

Because pop operations immediately return values that depend on the state of the queue (empty or nonempty), interleavings 1, 2, and 3 cannot be prevented by delaying pop operations until commit time. Instead, we can take one of two approaches:
\begin{enumerate}
    \item Optimistic: Abort $T1$ during commit time if $T2$ has committed an operation that would cause an invalid interleaving.
    \item Pessimistic: Prevent $T2$ from committing any operation until after $T1$ commits or aborts the transaction containing a pop.
\end{enumerate}

The T-QueueO implements the optimistic method: checks of the \texttt{tailversion} and \texttt{headversion} determine at commit time whether the empty status of the queue has been modified by another, already committed transaction. The T-QueueP implements the pessimistic approach, which locks the queue after a pop is performed and only releases the lock if the transaction commits or aborts, therefore preventing any other transaction from committing any operation after the pop.

To support transactions, the flat combining approach must do either approach (1) or (2). Here we argue that the flat combining approach cannot do either without introducing overhead that reduces its performance to below that of the T-QueueO or T-QueueP.

If we take approach (1), a pop cannot be performed at execution time because no locks on the queue are acquired: other transactions may commit pops of an invalid head if this transaction later aborts. Thus, in order to determine if a pop should return true or if it should return false, a transactional pop flat combining request requires much more complexity than a nontransactional one: the thread must determine how many elements the queue holds, how many elements the current transaction is intending to pop, and if any other thread intends to pop (in which case the transaction aborts). The transactional push flat combining request is also significantly more complex, as it requires installing all the pushes of the transaction. Additional flat combining calls are necessary to allow a thread to perform checks of the queue's empty status (the \texttt{<EMPTY?>} flat combining call) to determine whether the transaction can commit or must abort, and to actually execute the pops at commit time. Thus, approach (1) requires adding both more flat combining calls and more complexity to the existing flat combining calls.

If we take approach (2), the flat combining approach can either perform a pop at execution time or delay the pop until commit time. If the pop is performed at execution time, then the thread must acquire a global lock on the queue after a pop and hold the lock until commit: this prevents another thread from observing an inconsistent state of the queue. If a pop should execute and remove the head of the queue prior to commit and the transaction then aborts, the popped elements must be re-attached to the head of the queue. To ensure that no other thread can commit a transaction that pops off the incorrect head of the queue (given that elements will be reattached to the head), a global lock must be acquired by any transaction that performs a pop to allow for the case in which the transaction aborts. Additional flat combining calls are necessary to acquire or release the global lock. 

We can also imagine a mix of approaches (1) and (2) where if a transaction $T1$ executes a pop, we disallow any pops from other transactions (using the equivalent of a global lock) but allow other transactions containing only pushes to commit prior to $T1$ completing. This approach prevents interleavings 1 and 3, but requires performing a check of the queue's empty status, as in approach (1), if the queue is seen empty during a pop. This is because another transaction may have committed a push between the time of $T1$'s pop and $T1$'s completion. This mixed approach outperforms both approach (2) and approach (1), and is the approach described as the flat combining algorithm in Chapter~\ref{queue}. 

As noted previously, all possible approaches to prevent interleavings 1, 2, and 3 rely on additional flat combining calls and increased complexity of previously existing flat combining calls. In addition, acquisition of a global ``lock'' on the queue for approach (2) prevents the combiner thread from applying \emph{all} of the requests it sees: instead, requests will either return ``abort'' to the calling thread or not be applied, leading to additional time spent spinning or repeating requests. We see through our experiments that these changes to the flat combining algorithm reduce its performance such that it performs worse than a naive synchronization algorithm; furthermore, we claim that these changes are necessary in order to provide transactional guarantees. The original flat combining algorithm exploits the property that any correct history of operations in data structures supporting only singleton transactions (i.e., a normal non-transactional data structure) is valid. The combiner thread is allowed to immediately apply all thread's operation requests in arbitrary order. However, this property that makes flat combining so performant disappears as soon as the algorithm has to deal with invalid histories. In the next section, we demonstrate how ignoring invalid histories leads to a version of flat combining that can outperform our T-QueueO and T-QueueP algorithms: this supports our claim that the flat combining algorithm's performance is heavily dependent on what types of transactional guarantees it must provide.
