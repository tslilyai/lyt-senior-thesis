\section{FIFO Queue Algorithms and Analysis}
\label{Queue}

This chapter investigates different concurrent and transactional algorithms for queues, evaluates their performance, and draws conclusions about transactional algorithms more generally.


\subsection{Algorithms}

STO provides a transactional FIFO queue that adheres to the interface exposed by the C++ standard library queue. Here we detail different transactional queue algorithms that we implemented. This include both ones based off of standard transactional programming techniques and ones based off of highly-concurrent queue algorithms, namely Flat Combining.

A concurrent queue must adhere to the following specification, in which all operations can be ordered such that:
\begin{bullets}
    \item A value is \texttt{pop}ped off the queue only once (no duplicate \texttt{pop}s)
    \item A value is \texttt{push}ed onto the queue only once (no duplicate \texttt{push}es)
    \item Values are \texttt{pop}ped in the order in which they are \texttt{push}ed
\end{bullets}

A transactional queue adds the following invariants to the specification; there must be a serial order of all transactions such that, within one transaction:
\begin{bullets}
    \item Any two \texttt{pop}s pop consecutive values in the queue starting from the head of the queue 
    \item Any two \texttt{push}es push consecutive values at the tail of the queue
\end{bullets}

To satisfy these invariants, transactional data structures must support \emph{read-my-writes}. This is when a thread sees and modifies or returns the value from a previous operation in the transaction.

The STO data type algorithms enforce transactonal correctness using \emph{versions}. A version can act as a lock on the data structure: in order to update the data structure, a thread must first lock the version. A version also tracks changes to the data structure because it monotonically increases when a thread modifies the data structure. Thus, any version seen by a thread is equivalent to some previous or current state of the data structure. The first instance of the version observed by a thread during a transaction is checked when the transaction commits. This ensures that all observations are valid. Note that we cannot update the read version to an instance observed later in the transaction because we need to validate the first time we see the version in the transaction. 


\subsubsection{STO1 Queue}
\input{sto1table.tex}
The STO1 Queue is the first implementation of the transactional queue data structure using STO’s framework. It implements a circular, fixed-size transactional queue.

The queue is implemented using optimistic concurrency control (OCC), which is a transactional algorithm that optimistically assumes that no other transaction will conflict with a thread’s transaction. No thread prevents another thread from operating simultaneously on the queue during a transaction, which means multiple threads can add read/writes of the same parts of the queue during their transactions. Contention only occurs during commit time, when the thread must necessarily lock the queue so that it can safely verify and modify the queue’s values without parallel modifications by other threads. A thread can only realize that another thread has “beaten” it to modifying the queue at commit time.

There are two versions for the queue that can potentially invalidate a transaction if either changes: a headversion, and a tailversion. The headversion tracks the location of the head of the queue, and the tailversion tracks the location of the tail of the queue.

The queue supports three transactional operations: \texttt{push}, \texttt{pop}, and \texttt{front}. A \texttt{push} within a transaction adds to an internal \texttt{write\_list\_item}. This \texttt{write\_list} holds thread-local list of values to be \texttt{push}ed onto the queue, which are added to the tail of the queue during commit time (ensuring all values are added consecutively). We observe that all transactions comprised of only \texttt{push}es will always commit because \texttt{push}es do not observe any property of the queue: one transaction’s \texttt{push}es, \texttt{front}s, or \texttt{pop}s do not affect the outcome of another’s \texttt{push}es. (Note, however, that the opposite is not true). During commit time, the thread locks the tailversion so that no other thread’s \texttt{push} can push onto the queue. The items on the \texttt{write\_list} are added to the queue, and the tailversion incremented.

A \texttt{pop} within a transaction first checks if the queue is empty. If the queue is empty, then the thread reads the tailversion to ensure that no other transaction has committed a \texttt{push} before this thread commits. Suppose another thread successfully installs a \texttt{push} before this thread commits. Then this \texttt{pop} should have read that \texttt{push}ed value instead of seeing an empty queue. This forces the thread to abort the transaction. If there have been items added to the \texttt{write\_list} from previous \texttt{push}es within the transaction, then the \texttt{pop} will “pop” an item off the \texttt{write\_list}, performing an instance of \emph{read-my-writes}. Such a modiicatio is allowable during execution time because the \texttt{write\_list} is thread-local. If the queue is nonempty, then the thread reads the headversion to ensure that no other transaction has committed a \texttt{pop} before this thread commits. The thread then finds the item to pop off the queue by iterating through the queue from the head until it finds an item that has not yet been \texttt{pop}ped off within this transaction. The thread adds a write to this item so it knows during commit time and during future \texttt{pop}s that it intends to pop this item.

A \texttt{front} within a transaction is similar to a \texttt{pop}, excluding the iteration procedure to find the item to return (the value at the head of the queue or the \texttt{write\_list} is always returned). The queue is not modified, but the versions are read appropriately to ensure that the values returned by the \texttt{front} are still valid at commit time.

The design is summarized in Table \ref{table:sto1}.

\subsubsection{STO2 Queue}
\input{sto2table.tex}
The STO2 Queue is also a circular, fixed-size queue, with operations \texttt{push}, \texttt{pop}, and \texttt{front}. The STO2 Queue algorithm is a hybrid design integrating the STO1 algorithm with another transactional algorithm: pessimistic locking. This takes inspiration from the transactional queue from the Transactional Data Structures Library [1] as described in previous work. Their pessimistic transactional queue appears to achieve better performance in their benchmarks than the STO1 queue, and the algorithm is simpler to implement and describe. 

Pessimistic locking entails locking the queue when any naturally-contentious operation---\texttt{pop} or \texttt{front}--- is invoked. The queue is then only unlocked after the transaction is complete. This ensures that no other thread will execute an operation that may invalidate a \texttt{pop} or \texttt{front} within this thread’s transaction. However, operations such as “\texttt{push}” which can operate without any wait do not require locking during execution. Therefore, a \texttt{push} follows the same protocol as in the STO1 queue.

Because \texttt{pop} and \texttt{front} lock the queue, there are no conflicts at commit time. A thread only aborts if it fails to obtain the lock after a bounded period of time. The one version, “queueversion,” acts as the global queuelock. 

The algorithms are summarized in Table \ref{table:sto2}

\subsubsection{Flat Combining Queue (Non-Transactional)}

\emph{In the following discussion of our flat combining-based queues, we omit the discussion of the \texttt{front} operation to simplify reasoning about the state of the queue. An appropriate algorithm for \texttt{front} can be easily inferred from those used for \texttt{pop}.}

Flat Combining, proposed by Hendler, et. al. in 2010\cite{flatcombining}, is a synchronization technique that is based upon coarse-grained locking and single-thread access to the data structure. The key insight is that the cost of synchronization for certain classes of data structures often outweighs the benefits gained from parallelizing access to the data structure. These data structures include high-contention data structures such as stacks, queues, and priority queues. Created with this insight, the flat combining algorithm proposes a simple, thread-local synchronization technique that allows only one thread to ever access the data structure at once. This both reduces synchronization overhead on points of contention (such as the head of the queue) and achieves better cache performance by leveraging the single-threaded access patterns during data structure design.

The data structure design includes a sequential implementation of the data structure, a global lock, and per-thread records that are linked together in a global publication list. A record allows a thread to publish to other threads the specifics of any operation it wants to perform; the result of the operation is subsequently written to and retrieved from the record.

When a thread T wishes to do an operation O:
\begin{ordlist}
    \item T writes the opcode and parameters for O to its local record. Specifically for the queue, the thread writes \texttt{<PUSH, value>} or \texttt{<POP, 0>} to its local record.
   \item T tries to acquire the global lock.
   \begin{ordlist}
        \item T acquires the lock and is now the “combiner” thread. T applies all thread requests in the publication list to the data structure in sequence, and writes both the result and an \texttt{<OK>} response to each requesting thread’s local record.
        \item T failed to acquire the lock. T spins on its record until another thread has written the result to T’s record with the response \texttt{<OK>}.
    \end{ordlist}
\end{ordlist}

In the context of the queue, flat combining proves to be an effective technique to handle the contention caused by parallel access on the head and tail of the queue. In addition, their choice of queue implementation uses “fat nodes” (arrays of values, with new nodes allocated when the array fills up), which both improves cache performance and allows the queue to be dynamically sized. Both the STO1 and STO2 queues suffer from the contention and cache performance issues pointed out in the flat combining paper, leading us to believe that flat combining’s alternative synchronization paradigm might improve the performance of a transactional queue as much as it does for a concurrent queue.

\subsubsection{Flat Combining Queue (Transactional)}
\input{fctable.tex}

Recall that, in addition to the requirements for a correct concurrent queue, a transaction queue must guarantee that there must be a serial order of all transactions such that, within one transaction, any two pops pop consecutive values in the queue starting from the head of the queue and any two \texttt{push}es push consecutive values at the tail of the queue.

In order to add transactional guarantees to the flat combining queue, the order in which threads’ requests are applied to the queue becomes important. For example, let a transaction in thread T1 be \texttt{pop, pop} and a transaction in thread T2 be \texttt{pop}. The combiner thread sees \texttt{T1:pop} and \texttt{T2:pop}, and applies both operations to the queue. T1 second \texttt{pop} request will violate the transactional specification because the two \texttt{pop}ped values in T1’s transaction will not be consecutive. T1 must now abort, which means T2’s \texttt{pop} is now invalid: it does not represent a \texttt{pop} at the head of the queue.

Addressing the scenario described above requires two important changes to flat combining: 
\begin{ordlist}
\item \texttt{pop}s and \texttt{push}es cannot be applied to the queue during a transaction’s execution, and must instead be performed when a transaction commits
\item Because of (1), values remain in the queue even when a transaction has previously performed a \texttt{pop}. Thus, the algorithm must track which values in the queue are going to be \texttt{pop}ped within the transaction in order to prevent duplicate \texttt{pop}s.
\end{ordlist}

We now describe the new algorithms for \texttt{push} and \texttt{pop}.  We change the types of request a thread can publish to its record on the publication list. Recall that the original flat combining queue supports two requests: \texttt{<PUSH, value>} and \texttt{<POP, 0>}. The transactional queue supports the follow requests:
\begin{bullets}
    \item \texttt{<PUSH, list>} : \texttt{push} a list of values onto the queue
    \item \texttt{<MARK\_POP, thread\_id>} : mark a value in the queue to be \texttt{pop}ped by this \texttt{thread\_id}
    \item \texttt{<DEQ, thread\_id>} : dequeue all values in the queue that are marked by this \texttt{thread\_id}
    \item \texttt{<EMPTY?, thread\_id>} : check if the queue, after \texttt{pop}ping all items marked by this \texttt{thread\_id}, is empty
    \item \texttt{<CLEANUP, thread\_id>} : unmark all values that are marked with this \texttt{thread\_id}
\end{bullets}

As with the STO1 queue, a \texttt{push} within a transaction adds to an internal \texttt{write\_list\_item}. At commit time, the thread will invoke the \texttt{<PUSH, list>}, with the \texttt{write\_list} passed as the argument.

A \texttt{pop} within a transaction invokes the \texttt{<MARK\_POP, thread\_id>} command. The combiner thread, upon seeing a MARK\_POP command, looks at the first value at the head of the queue. If this value is marked with another thread’s \texttt{thread\_id}, the combiner thread returns \texttt{<ABORT>} to the calling thread. If the value is not marked, the combiner thread marks the value with the caller’s \texttt{thread\_id} and returns \texttt{<OK>}. Else the value is marked by the calling thread’s \texttt{thread\_id}. In this scenario, note that no other thread will have marked values in the queue, since they will abort when seeing the head value marked by the calling thread’s \texttt{thread\_id}. The combiner thread iterates sequentially through the queue values until it reaches a value not marked by the calling thread’s \texttt{thread\_id}. It then marks the value with the caller’s \texttt{thread\_id} and returns \texttt{<OK>}. Upon receiving the response, the calling thread adds a write to a \texttt{pop\_item} to tell the thread to post a \texttt{<DEQ, thread\_id>} request at commit time. This removes the popped value from the queue.

If the queue is either empty or there are no values not marked with the caller’s \texttt{thread\_id}, the combiner thread will return \texttt{<EMPTY>}, which is remembered by the calling thread. An \texttt{<EMPTY>} response requires that the size of the queue be checked at commit time.

Note that this algorithm does not allow \texttt{pop}s to read the values \texttt{push}ed within the same transaction. To do so would require passing in the thread’s \texttt{write\_list} in addition to the \texttt{thread\_id} as arguments to the combiner thread. For the sake of our evaluation, we leave this part of the transactional queue specification unimplemented.

The \texttt{<EMPTY?, thread\_id>} request is posted when a thread attempts to commit a transaction that observed an empty queue at some point in its execution. This happens when the thread receives an \texttt{<EMPTY>} response to a \texttt{<MARK\_POP>} request during the transaction. If the response to \texttt{<EMPTY?>} is true, then the thread knows that no other thread has \texttt{push}ed onto the queue between the time of its \texttt{<MARK\_POP>} seeing an empty queue and commit time. Else another thread has \texttt{push}ed items onto the queue, invalidating this thread’s \texttt{pop} result, and this thread must abort.

The \texttt{<CLEANUP, thread\_id>} request is posted when a thread aborts a transaction and must unmark any items in the queue that it had marked as pending \texttt{pop}s. The combiner thread iterates through the queue from the head and unmarks any items with the \texttt{thread\_id}.

The algorithm is summarized in Table \ref{table:fc}.

\subsection{Evaluation}

\subsubsection{Benchmark Parameters}
\begin{bullets}
\item Value Types: Each queue benchmark uses randomly chosen integers. This is because the benchmark tests do not manipulate the values they push/pop and the queue algorithms are agnostic to the actual values being placed in the queue.

\item Initial Queue Size: We run several tests with different initial fullness of the data structure. This affects how often the structure becomes empty, which can cause aborts and additional overhead (as described in the algorithms above). It also affects the number of cache lines accessed: a near-empty queue will never require iterating over values contained in more than one cache line.

\item Transaction Size: We modify the number of operations per transaction in different benchmarks. For some benchmarks, the number of operations in a transaction for our benchmarks is set to 1. This minimizes the overhead added to support multiple-operation transactions. The overhead includes support for multiple items in read/write sets, read-my-writes, and an increased number of aborts and retries. With single operation transactions, we observe an upper bound on the best performance our data structures can achieve. We also can more easily compare the performance of a transactional data structure with a nontransactional concurrent data structure.

\item Data Structure Opacity: If opacity is enabled, a transaction will abort immediately if any inconsistent state is detected. \lyt{MORE HERE?}. This requires keeping track of a global transaction ID (TID). This global TID must be accessed when a transaction commits and when items are added to the read set during a transaction's, making transactions overall more expensive.
\end{bullets}

\subsubsection{Benchmarks Tests}
\begin{ordlist}
\item 2-Thread Push-Pop Test: This test has one thread that performs only \texttt{push}es and another thread that performs only \texttt{pops}. Unless the queue is empty, the two threads should never be modifying the same part of the data structure, and will never conflict (abort rate should be near 0).

\item Multi-Thread Random Single-Operation Transaction Test: 
    In this test, a thread randomly selects an operation (\texttt{push} or \texttt{pop}) to perform within each transaction. This keeps the queue at approximately the same size as its initial size during the test. This test is run with different initial queue sizes and different numbers of threads.
    
\item Multi-Thread Random Multi-Operation Transaction Test: 
    In this test, a thread randomly selects multiple operations (\texttt{push} or \texttt{pop}) to perform within each transaction. This keeps the queue at approximately the same size as its initial size during the test. This test is run with different initial queue sizes and different numbers of threads.
    
\end{ordlist}

\subsubsection{Results}

\subsection{Discussion and Conclusions}

